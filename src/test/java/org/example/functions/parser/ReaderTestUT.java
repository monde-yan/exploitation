package org.example.functions.parser;

import DeplacementPresidentFunction.Parser.DeplacementPresidentStatFunction;
import DeplacementPresidentFunction.DeplacementPresidentReader.DeplacementPresidentReader;
import beans.DeplacementPresident;
import lombok.SneakyThrows;
import org.apache.hadoop.fs.FileSystem;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.junit.Test;

import static org.junit.Assert.assertTrue;

public class  ReaderTestUT {

    @SneakyThrows
    @Test
    public void testReader() {

        String inputpath = "src/test/resources/data/input/deplacements-presidents-republique-et-premiers-ministres-depuis-1945.csv";

        SparkSession sparkSession = SparkSession.builder()
                .master("local[2]")
                .appName("testStatistic")
                .getOrCreate();
        DeplacementPresidentStatFunction y = new DeplacementPresidentStatFunction();
        FileSystem hdfs = FileSystem.get(sparkSession.sparkContext().hadoopConfiguration());
        DeplacementPresidentReader reader = new DeplacementPresidentReader(sparkSession, hdfs,inputpath);
        Dataset<DeplacementPresident> dataset = reader.get();

        assertTrue(dataset.count() > 0);
    }
}
